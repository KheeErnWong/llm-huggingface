{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d92eeb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from sklearn.datasets import make_classification\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5014493b",
   "metadata": {},
   "source": [
    "# Find covariance of matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "4d5f1063",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[1, 2, 3], [4, 5, 6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c50755a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0, 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean of each row\n",
    "mean = []\n",
    "\n",
    "# Change into list comprehension later\n",
    "for row in matrix:\n",
    "    mean_row = sum(row) / len(matrix[0])\n",
    "    mean.append(mean_row)\n",
    "\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3da13ece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.0, 0.0, 1.0], [-1.0, 0.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "# Center each row by subtracting it's mean\n",
    "centered = []\n",
    "\n",
    "for i in range(len(matrix)):\n",
    "    centered_row = []\n",
    "    for j in range(len(matrix[0])):\n",
    "        centered_row.append(matrix[i][j] - mean[i])\n",
    "\n",
    "    centered.append(centered_row)\n",
    "\n",
    "print(centered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0055ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "# DRY: Convert matrix[0] to a common variable\n",
    "\n",
    "multiplied = []\n",
    "for j in range(len(matrix[0])):\n",
    "    product = 1\n",
    "    sum = 0\n",
    "    for i in range(len(matrix)):\n",
    "        product *= centered[i][j]\n",
    "        sum += product\n",
    "    print(sum)\n",
    "\n",
    "print(multiplied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017295d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Covariance\n",
    "covariance = sum(multiplied) / (len(multiplied) - 1)\n",
    "print(covariance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "026a9c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.],\n",
       "       [1., 1.]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7821ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ee9d10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d7d20bf",
   "metadata": {},
   "source": [
    "# Eigen values and eigenvectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e8c378db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1], [1, 2]]\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "matrix = [[2, 1], [1, 2]]\n",
    "n = len(matrix)\n",
    "print(matrix)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3a5a7ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity = []\n",
    "for i in range(n):\n",
    "    row = []\n",
    "    for j in range(n):\n",
    "        row.append(1 if i == j else 0)\n",
    "    identity.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fca42f8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 0], [0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1352f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "-4\n",
      "3\n",
      "3.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Use quadratic equation to solve for lambda (eigenvalue)\n",
    "## Store quadratic equation variables first\n",
    "a = 1\n",
    "b = -matrix[0][0] - matrix[1][1]\n",
    "c = matrix[0][0] * matrix[1][1] - matrix[0][1] * matrix[1][0]\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "\n",
    "## Calc lambda\n",
    "lambda_1 = (-b + np.sqrt(b**2 - 4 * a * c)) / (2 * a)\n",
    "lambda_2 = (-b - np.sqrt(b**2 - 4 * a * c)) / (2 * a)\n",
    "\n",
    "print(lambda_1)\n",
    "print(lambda_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0a7dacd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[np.float64(3.0), np.float64(1.0)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvalues = sorted([lambda_1, lambda_2], reverse=True)\n",
    "eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e1e057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b594fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075937ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41065b54",
   "metadata": {},
   "source": [
    "# Multiply matrix by scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb20b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[1, 2, 3], [4, 5, 6]]\n",
    "scalar = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4ec68781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "n_rows = len(matrix)\n",
    "n_cols = len(matrix[0])\n",
    "print(n_rows)\n",
    "print(n_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "8ddb661d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 4, 6], [8, 10, 12]]\n"
     ]
    }
   ],
   "source": [
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        matrix[row][col] *= 2\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8db746d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6, 8])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list = [1, 2, 3, 4]\n",
    "list = np.array(list)\n",
    "list *= 2\n",
    "list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72036db",
   "metadata": {},
   "source": [
    "# Calculate mean y row/col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd0f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
    "mode = \"column\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "91281053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc mean by col\n",
    "n_cols = len(matrix[0])\n",
    "n_rows = len(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "642a4db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 5.0, 8.0]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calc mean by row\n",
    "mean = [sum(row) / len(row) for row in matrix]\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "95074e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calc mean by col\n",
    "result = []\n",
    "\n",
    "mean = [\n",
    "    sum(matrix[row][col] for row in range(n_rows)) / n_rows for col in range(n_cols)\n",
    "]\n",
    "\n",
    "for col in range(n_cols):\n",
    "    column_sum = 0\n",
    "    for row in range(n_rows):\n",
    "        column_sum += matrix[row][col]\n",
    "    mean = column_sum / n_rows\n",
    "    result.append(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a29e837",
   "metadata": {},
   "source": [
    "# Reshape matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ba7b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2, 3, 4], [5, 6, 7, 8]]\n",
    "new_shape = (4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3654415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat = [elem for row in a for elem in row]\n",
    "reshaped = [flat[i : i + 2] for i in range(0, len(flat), 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2b1ef876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2], [3, 4], [5, 6], [7, 8]]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84dcbea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10ed26b5",
   "metadata": {},
   "source": [
    "# Transpose matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2740316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1, 2, 3], [4, 5, 6]]\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e5630",
   "metadata": {},
   "outputs": [],
   "source": [
    "tranposed = []\n",
    "\n",
    "transposed = [[a[row][col] for row in range(len(a))] for col in range(len(a[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07a25478",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 4], [2, 5], [3, 6]]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transposed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a16b5",
   "metadata": {},
   "source": [
    "# Matrix dot vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e748c409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5, 10])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[1, 2], [2, 4]]\n",
    "b = [1, 2]\n",
    "\n",
    "result = np.dot(a, b)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b5534d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "n_rows = len(a)\n",
    "n_cols = len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9f81a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if n_rows != n_cols\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f831951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 10]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for row in range(len(a)):\n",
    "    dot = sum(a[row][col] * b[col] for col in range(len(b)))\n",
    "    result.append(dot)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d7e53",
   "metadata": {},
   "source": [
    "# Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3f0f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(seq_len, d_model):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        seq_len: Max sequence length\n",
    "        d_model: Embedding dimension\n",
    "    Returns:\n",
    "        PE matrix (seq_len, d_model)\n",
    "    \"\"\"\n",
    "    pe = np.zeros((seq_len, d_model))\n",
    "    position = np.arange(seq_len).reshape(-1, 1)\n",
    "    div_term = np.exp(np.arange(0, d_model, 2) * -(np.log(10000.0) / d_model))\n",
    "    pe[:, 0::2] = np.sin(position * div_term)\n",
    "    pe[:, 1::2] = np.cos(position * div_term)\n",
    "\n",
    "    return pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c5788d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 10\n",
    "d_model = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84f15702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 8.41470985e-01  5.40302306e-01  1.57826640e-01  9.87466836e-01\n",
      "   2.51162229e-02  9.99684538e-01  3.98106119e-03  9.99992076e-01\n",
      "   6.30957303e-04  9.99999801e-01]\n",
      " [ 9.09297427e-01 -4.16146837e-01  3.11697146e-01  9.50181503e-01\n",
      "   5.02165994e-02  9.98738351e-01  7.96205928e-03  9.99968302e-01\n",
      "   1.26191435e-03  9.99999204e-01]\n",
      " [ 1.41120008e-01 -9.89992497e-01  4.57754548e-01  8.89078609e-01\n",
      "   7.52852930e-02  9.97162035e-01  1.19429312e-02  9.99928681e-01\n",
      "   1.89287090e-03  9.99998209e-01]\n",
      " [-7.56802495e-01 -6.53643621e-01  5.92337725e-01  8.05689779e-01\n",
      "   1.00306487e-01  9.94956586e-01  1.59236138e-02  9.99873211e-01\n",
      "   2.52382670e-03  9.99996815e-01]\n",
      " [-9.58924275e-01  2.83662185e-01  7.12073170e-01  7.02105263e-01\n",
      "   1.25264396e-01  9.92123395e-01  1.99040441e-02  9.99801895e-01\n",
      "   3.15478149e-03  9.99995024e-01]\n",
      " [-2.79415498e-01  9.60170287e-01  8.13959555e-01  5.80921547e-01\n",
      "   1.50143272e-01  9.88664249e-01  2.38841589e-02  9.99714733e-01\n",
      "   3.78573502e-03  9.99992834e-01]\n",
      " [ 6.56986599e-01  7.53902254e-01  8.95442962e-01  4.45176260e-01\n",
      "   1.74927419e-01  9.84581331e-01  2.78638951e-02  9.99611726e-01\n",
      "   4.41668705e-03  9.99990246e-01]\n",
      " [ 9.89358247e-01 -1.45500034e-01  9.54480901e-01  2.98272038e-01\n",
      "   1.99601200e-01  9.79877217e-01  3.18431897e-02  9.99492877e-01\n",
      "   5.04763732e-03  9.99987261e-01]\n",
      " [ 4.12118485e-01 -9.11130262e-01  9.89593509e-01  1.43891232e-01\n",
      "   2.24149048e-01  9.74554875e-01  3.58219797e-02  9.99358187e-01\n",
      "   5.67858558e-03  9.99983877e-01]]\n"
     ]
    }
   ],
   "source": [
    "pe = positional_encoding(10, 10)\n",
    "print(pe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69662801",
   "metadata": {},
   "source": [
    "# Self attention mechanism implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8a97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is the softmax using np.max() and not max()?\n",
    "# Give me the formula for softmax, and also why axis=-1 and keepdims=True\n",
    "# softmax(x) = np.exp(x)/sum(np.exp(x))\n",
    "def softmax(x, axis=-1):\n",
    "    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8da3d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(X, W_q, W_k, W_v):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X: Input matrix (seq_len, d_model)\n",
    "        W_q: Query weight matrix (d_model, d_k)\n",
    "        W_k: Key weight matrix (d_model, d_k)\n",
    "        W_v: Value weight matrix (d_model, d_k)\n",
    "\n",
    "    Returns:\n",
    "        Output matrix (seq_len, d_v)\n",
    "    \"\"\"\n",
    "\n",
    "    # Project inputs to QKV\n",
    "    Q = X @ W_q\n",
    "    K = X @ W_k\n",
    "    V = X @ W_v\n",
    "\n",
    "    # Calculate attention score\n",
    "    d_k = Q.shape[-1]\n",
    "    scores = Q @ K.T / np.sqrt(d_k)  # (seq_len, seq_len)\n",
    "\n",
    "    # Apply softmax to get attention weights\n",
    "    attention_weights = softmax(scores, axis=-1)  # (seq_len, seq_len)\n",
    "\n",
    "    # Weighted sum of values\n",
    "    output = attention_weights @ V  # (seq_len, d_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4e4254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_head_attention(X, num_heads, W_q, W_k, W_v, W_o):\n",
    "    seq_len, d_model = X.shape\n",
    "    d_k = d_model // num_heads\n",
    "\n",
    "    # Project and split into heads\n",
    "    Q = (X @ W_q).reshape(seq_len, num_heads, d_k)\n",
    "    K = (X @ W_k).reshape(seq_len, num_heads, d_k)\n",
    "    V = (X @ W_v).reshape(seq_len, num_heads, d_k)\n",
    "\n",
    "    # Transpose for batche computation: (num_heads, seq_len, d_k)\n",
    "    Q = Q.transpose(1, 0, 2)\n",
    "    K = K.transpose(1, 0, 2)\n",
    "    V = V.transpose(1, 0, 2)\n",
    "\n",
    "    # Attention per head\n",
    "    scores = Q @ K.transpose(0, 2, 1) / np.sqrt(d_k)  # (num_heads, seq_len, seq_len)\n",
    "    attention_weights = softmax(scores, axis=-1)\n",
    "    head_outputs = attention_weights @ V  # (num_heads, seq_len, d_k)\n",
    "\n",
    "    # Concat heads and project\n",
    "    concat = head_outputs.transpose(1, 0, 2).reshape(\n",
    "        seq_len, d_model\n",
    "    )  # (seq_len, d_model)\n",
    "    output = concat @ W_o  # (seq_len, d_model). W_o (d_model, d_model)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee168f0",
   "metadata": {},
   "source": [
    "# Feature depency resolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e6517",
   "metadata": {},
   "outputs": [],
   "source": [
    " class FeatureDependencyResolver:\n",
    "      def __init__(self, dependencies: dict):\n",
    "          # Build graph structure\n",
    "          pass\n",
    "\n",
    "      def topological_sort(self) -> list:\n",
    "          # Return valid computation order\n",
    "          pass\n",
    "\n",
    "      def has_cycle(self) -> bool:\n",
    "          # Return True if circular dependency exists\n",
    "          pass\n",
    "\n",
    "      def compute_parallel_batches(self) -> list:\n",
    "          # Return list of batches (each batch is a list of features)\n",
    "          pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb062dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = {\n",
    "    \"raw_price\": [],\n",
    "    \"raw_volume\": [],\n",
    "    \"returns\": [\"raw_price\"],\n",
    "    \"volatility\": [\"returns\"],\n",
    "    \"volume_ma\": [\"raw_volume\"],\n",
    "    \"price_volume_corr\": [\"returns\", \"volume_ma\"],\n",
    "    \"risk_score\": [\"volatility\", \"price_volume_corr\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "fb26e755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'raw_price': 0, 'raw_volume': 0, 'returns': 1, 'volatility': 1, 'volume_ma': 1, 'price_volume_corr': 2, 'risk_score': 2}\n"
     ]
    }
   ],
   "source": [
    "# Build in-degree map\n",
    "## Build a new dict that has feature as key, and the no. of dependencies as value\n",
    "in_degree = {feature: len(deps) for feature, deps in dependencies.items()}\n",
    "print(in_degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "b06ecf09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deque(['raw_price', 'raw_volume'])\n"
     ]
    }
   ],
   "source": [
    "# Initialize queue with zero in-degree nodes\n",
    "queue = deque([feature for feature, degree in in_degree.items() if degree == 0])\n",
    "print(queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "62f1af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "while queue:\n",
    "    current = queue.popleft()\n",
    "    result.append(current)\n",
    "\n",
    "    # Decrease in-degree for features depending on current\n",
    "    for feature, deps in dependencies.items():\n",
    "        if current in deps:\n",
    "            in_degree[feature] -= 1\n",
    "            if in_degree[feature] == 0:\n",
    "                queue.append(feature)\n",
    "\n",
    "# Check for cycle\n",
    "if len(result) != len(dependencies):\n",
    "    raise ValueError(\"Circular dependency detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b90ec7c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['raw_price',\n",
       " 'raw_volume',\n",
       " 'returns',\n",
       " 'volume_ma',\n",
       " 'volatility',\n",
       " 'price_volume_corr',\n",
       " 'risk_score']"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7cc98855",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degree = {feature: len(dependency) for feature, dependency in dependencies.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75223a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque(['raw_price', 'raw_volume'])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queue = deque(feature for feature, depdendency in in_degree.items() if depdendency == 0)\n",
    "queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "501ce82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c232ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "while queue:\n",
    "    current = queue.popleft()\n",
    "    if not dependencies[current]:\n",
    "        batch_num[current] = 0\n",
    "    else:\n",
    "        batch_num[current] = (\n",
    "            max(batch_num[dependency] for dependency in dependencies[current]) + 1\n",
    "        )\n",
    "\n",
    "    for feature, dependency in dependencies.items():\n",
    "        if current in dependency:\n",
    "            in_degree[feature] -= 1\n",
    "            if in_degree[feature] == 0:\n",
    "                queue.append(feature)\n",
    "\n",
    "max_batch = max(batch_num.values())\n",
    "batches = [[] for _ in range(max_batch + 1)]\n",
    "\n",
    "for feature, batch in batch_num.items():\n",
    "    batches[batch].append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "8611d15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['raw_price', 'raw_volume'], ['volume_ma']]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0461b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_parallel_batches(dependencies: dict) -> list:\n",
    "    \"\"\"\n",
    "    Returns list of batches where each batch can execute in parallel.\n",
    "    Raises ValueError if circular dependency detected.\n",
    "    \"\"\"\n",
    "    # Step 1: Build reverse graph (who depends on me?)\n",
    "    graph = {feature: [] for feature in dependencies}\n",
    "    for feature, deps in dependencies.items():\n",
    "        for dep in deps:\n",
    "            graph[dep].append(feature)\n",
    "\n",
    "    # Step 2: Count incoming dependencies\n",
    "    in_degree = {feature: len(deps) for feature, deps in dependencies.items()}\n",
    "\n",
    "    # Step 3: Start with features that have no dependencies\n",
    "    queue = deque([f for f, degree in in_degree.items() if degree == 0])\n",
    "\n",
    "    # Step 4: Process in topological order, assign batch numbers\n",
    "    batch_num = {}\n",
    "\n",
    "    while queue:\n",
    "        current = queue.popleft()\n",
    "\n",
    "        # Assign batch: 0 if no deps, else max(dep batches) + 1\n",
    "        if len(dependencies[current]) == 0:\n",
    "            batch_num[current] = 0\n",
    "        else:\n",
    "            batch_num[current] = (\n",
    "                max(batch_num[dep] for dep in dependencies[current]) + 1\n",
    "            )\n",
    "\n",
    "        # Reduce in-degree for features that depend on current\n",
    "        for dependent in graph[current]:\n",
    "            in_degree[dependent] -= 1\n",
    "            if in_degree[dependent] == 0:\n",
    "                queue.append(dependent)\n",
    "\n",
    "    # Step 5: Check for cycles\n",
    "    if len(batch_num) != len(dependencies):\n",
    "        raise ValueError(\"Circular dependency detected\")\n",
    "\n",
    "    # Step 6: Group features by batch number\n",
    "    max_batch = max(batch_num.values())\n",
    "    batches = [[] for _ in range(max_batch + 1)]\n",
    "    for feature, batch in batch_num.items():\n",
    "        batches[batch].append(feature)\n",
    "\n",
    "    return batches\n",
    "\n",
    "\n",
    "def topological_sort(dependencies: dict) -> list:\n",
    "    \"\"\"Returns features in valid computation order.\"\"\"\n",
    "    batches = compute_parallel_batches(dependencies)\n",
    "    return [feature for batch in batches for feature in batch]\n",
    "\n",
    "\n",
    "def has_cycle(dependencies: dict) -> bool:\n",
    "    \"\"\"Returns True if circular dependency exists.\"\"\"\n",
    "    try:\n",
    "        compute_parallel_batches(dependencies)\n",
    "        return False\n",
    "    except ValueError:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70afb9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['raw_price', 'raw_volume'], ['returns', 'volume_ma'], ['volatility', 'price_volume_corr'], ['risk_score']]\n"
     ]
    }
   ],
   "source": [
    "dependencies = {\n",
    "    \"raw_price\": [],\n",
    "    \"raw_volume\": [],\n",
    "    \"returns\": [\"raw_price\"],\n",
    "    \"volatility\": [\"returns\"],\n",
    "    \"volume_ma\": [\"raw_volume\"],\n",
    "    \"price_volume_corr\": [\"returns\", \"volume_ma\"],\n",
    "    \"risk_score\": [\"volatility\", \"price_volume_corr\"],\n",
    "}\n",
    "\n",
    "# Get parallel batches\n",
    "batches = compute_parallel_batches(dependencies)\n",
    "print(batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77833ba4",
   "metadata": {},
   "source": [
    "# EWM Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "340265cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4)\n",
      "[[-1.05383855 -1.02754411 -0.32929388  0.82600732]\n",
      " [ 1.56931739  1.306542   -0.23938468 -0.3313761 ]\n",
      " [-0.35885569 -0.69102126 -1.22532865  1.65214494]\n",
      " [-0.1368559   0.46093758  1.89691056 -2.2813861 ]\n",
      " [-0.04862909  0.50230075  1.77872961 -2.17105282]]\n"
     ]
    }
   ],
   "source": [
    "returns, y = make_classification(n_features=4, random_state=42)\n",
    "print(returns.shape)\n",
    "print(returns[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179941da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ewm_covariance(returns: np.ndarray, decay: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Calculates exponentially weighted covariance matric\n",
    "    Args:\n",
    "        returns: Array of shape (n_days, n_assets) of daily returns\n",
    "        decay: Lambda parameter\n",
    "    Returns:\n",
    "        Covariance matrix\n",
    "    \"\"\"\n",
    "    # Get number of rows for weights calculation\n",
    "    n_days, n_assets = returns.shape\n",
    "\n",
    "    # Get exponents. Last row gets biggest number, oldest gets smallest\n",
    "    exponents = np.arange(n_days - 1, -1, -1)\n",
    "\n",
    "    # Calculate weights from exponents\n",
    "    weights = (1 - decay) * decay**exponents\n",
    "\n",
    "    # Normalize the weights\n",
    "    weights = weights / weights.sum()\n",
    "\n",
    "    # Calculated weighted mean\n",
    "    weighted_mean = np.dot(weights, returns)\n",
    "\n",
    "    # Get centered value\n",
    "    centered = returns - weighted_mean\n",
    "\n",
    "    # Math trick to calculate covariance\n",
    "    ## Calculate sqrt weights\n",
    "    sqrt_weights = np.sqrt(weights).reshape(-1, 1)\n",
    "    ## Calculated centered_weighted\n",
    "    centered_weighted = centered * sqrt_weights\n",
    "    cov_matrix = centered_weighted.T @ centered_weighted\n",
    "\n",
    "    return cov_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "76687393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.50304966,  0.96021459, -1.17942379,  0.85269747],\n",
       "       [ 0.96021459,  0.69266431, -0.49488971,  0.22630876],\n",
       "       [-1.17942379, -0.49488971,  1.76931393, -1.70826046],\n",
       "       [ 0.85269747,  0.22630876, -1.70826046,  1.76344153]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_matrix = ewm_covariance(returns, decay=0.94)\n",
    "cov_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d8f787",
   "metadata": {},
   "source": [
    "# Rolling risk metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1393d51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>daily_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>-0.008685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>0.026338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>-0.013153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>0.009876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.016493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dates  daily_return\n",
       "255 2023-12-25     -0.008685\n",
       "256 2023-12-26      0.026338\n",
       "257 2023-12-27     -0.013153\n",
       "258 2023-12-28      0.009876\n",
       "259 2023-12-29      0.016493"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input data\n",
    "np.random.seed(42)\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"dates\": pd.date_range(\"2023-01-01\", periods=260, freq=\"B\"),\n",
    "        \"daily_return\": pd.Series(np.random.normal(0.001, 0.02, 260)),\n",
    "    }\n",
    ")\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6764c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>volatility</th>\n",
       "      <th>std_dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>-0.008685</td>\n",
       "      <td>0.348853</td>\n",
       "      <td>0.021976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>0.026338</td>\n",
       "      <td>0.327260</td>\n",
       "      <td>0.020615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>-0.013153</td>\n",
       "      <td>0.332429</td>\n",
       "      <td>0.020941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.328648</td>\n",
       "      <td>0.020703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.016493</td>\n",
       "      <td>0.327788</td>\n",
       "      <td>0.020649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dates  daily_return  volatility   std_dev\n",
       "255 2023-12-25     -0.008685    0.348853  0.021976\n",
       "256 2023-12-26      0.026338    0.327260  0.020615\n",
       "257 2023-12-27     -0.013153    0.332429  0.020941\n",
       "258 2023-12-28      0.009876    0.328648  0.020703\n",
       "259 2023-12-29      0.016493    0.327788  0.020649"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"std_dev\"] = df[\"daily_return\"].rolling(window=20).std()\n",
    "df[\"volatility\"] = df[\"std_dev\"] * np.sqrt(252)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be76aa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>volatility</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>sharpe_ratio</th>\n",
       "      <th>mean_return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>2023-12-25</td>\n",
       "      <td>-0.008685</td>\n",
       "      <td>0.348853</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>2023-12-26</td>\n",
       "      <td>0.026338</td>\n",
       "      <td>0.327260</td>\n",
       "      <td>0.020615</td>\n",
       "      <td>2.635700</td>\n",
       "      <td>0.003423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2023-12-27</td>\n",
       "      <td>-0.013153</td>\n",
       "      <td>0.332429</td>\n",
       "      <td>0.020941</td>\n",
       "      <td>1.916923</td>\n",
       "      <td>0.002529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2023-12-28</td>\n",
       "      <td>0.009876</td>\n",
       "      <td>0.328648</td>\n",
       "      <td>0.020703</td>\n",
       "      <td>2.786730</td>\n",
       "      <td>0.003634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2023-12-29</td>\n",
       "      <td>0.016493</td>\n",
       "      <td>0.327788</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>2.734229</td>\n",
       "      <td>0.003557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dates  daily_return  volatility   std_dev  sharpe_ratio  mean_return\n",
       "255 2023-12-25     -0.008685    0.348853  0.021976      0.094488     0.000131\n",
       "256 2023-12-26      0.026338    0.327260  0.020615      2.635700     0.003423\n",
       "257 2023-12-27     -0.013153    0.332429  0.020941      1.916923     0.002529\n",
       "258 2023-12-28      0.009876    0.328648  0.020703      2.786730     0.003634\n",
       "259 2023-12-29      0.016493    0.327788  0.020649      2.734229     0.003557"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"mean_return\"] = df[\"daily_return\"].rolling(window=20).mean()\n",
    "df[\"sharpe_ratio\"] = df[\"mean_return\"] / df[\"std_dev\"] * np.sqrt(252)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c7bf6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cumulative_wealth\"] = (1 + df[\"daily_return\"]).cumprod()\n",
    "df[\"rolling_peak\"] = df[\"cumulative_wealth\"].rolling(window=60).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7363574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>volatility</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>sharpe_ratio</th>\n",
       "      <th>mean_return</th>\n",
       "      <th>cumulative_wealth</th>\n",
       "      <th>rolling_peak</th>\n",
       "      <th>drawdown</th>\n",
       "      <th>max_drawdown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>0.010934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.010934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-01-03</td>\n",
       "      <td>-0.001765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-04</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.023231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>0.031461</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.055423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>-0.003683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.051535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>-0.003683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.047663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2023-01-10</td>\n",
       "      <td>0.032584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.081800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2023-01-11</td>\n",
       "      <td>0.016349</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.099486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023-01-12</td>\n",
       "      <td>-0.008389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.090262</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>0.011851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.103183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2023-01-16</td>\n",
       "      <td>-0.008268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.094061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2023-01-17</td>\n",
       "      <td>-0.008315</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.084965</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2023-01-18</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.091300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2023-01-19</td>\n",
       "      <td>-0.037266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2023-01-20</td>\n",
       "      <td>-0.033498</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.015438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2023-01-23</td>\n",
       "      <td>-0.010246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.005034</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2023-01-24</td>\n",
       "      <td>-0.019257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2023-01-25</td>\n",
       "      <td>0.007285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2023-01-26</td>\n",
       "      <td>-0.017160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.975823</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2023-01-27</td>\n",
       "      <td>-0.027246</td>\n",
       "      <td>0.3048</td>\n",
       "      <td>0.019201</td>\n",
       "      <td>-2.005727</td>\n",
       "      <td>-0.002426</td>\n",
       "      <td>0.949236</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        dates  daily_return  volatility  ...  rolling_peak  drawdown  max_drawdown\n",
       "0  2023-01-02      0.010934         NaN  ...           NaN       NaN           NaN\n",
       "1  2023-01-03     -0.001765         NaN  ...           NaN       NaN           NaN\n",
       "2  2023-01-04      0.013954         NaN  ...           NaN       NaN           NaN\n",
       "3  2023-01-05      0.031461         NaN  ...           NaN       NaN           NaN\n",
       "4  2023-01-06     -0.003683         NaN  ...           NaN       NaN           NaN\n",
       "5  2023-01-09     -0.003683         NaN  ...           NaN       NaN           NaN\n",
       "6  2023-01-10      0.032584         NaN  ...           NaN       NaN           NaN\n",
       "7  2023-01-11      0.016349         NaN  ...           NaN       NaN           NaN\n",
       "8  2023-01-12     -0.008389         NaN  ...           NaN       NaN           NaN\n",
       "9  2023-01-13      0.011851         NaN  ...           NaN       NaN           NaN\n",
       "10 2023-01-16     -0.008268         NaN  ...           NaN       NaN           NaN\n",
       "11 2023-01-17     -0.008315         NaN  ...           NaN       NaN           NaN\n",
       "12 2023-01-18      0.005839         NaN  ...           NaN       NaN           NaN\n",
       "13 2023-01-19     -0.037266         NaN  ...           NaN       NaN           NaN\n",
       "14 2023-01-20     -0.033498         NaN  ...           NaN       NaN           NaN\n",
       "15 2023-01-23     -0.010246         NaN  ...           NaN       NaN           NaN\n",
       "16 2023-01-24     -0.019257         NaN  ...           NaN       NaN           NaN\n",
       "17 2023-01-25      0.007285         NaN  ...           NaN       NaN           NaN\n",
       "18 2023-01-26     -0.017160         NaN  ...           NaN       NaN           NaN\n",
       "19 2023-01-27     -0.027246      0.3048  ...           NaN       NaN           NaN\n",
       "\n",
       "[20 rows x 10 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd93116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"max_drawdown\"] = df[\"drawdown\"].rolling(window=60).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f239204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2514226354265785\n"
     ]
    }
   ],
   "source": [
    "print(df[\"max_drawdown\"].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451c0836",
   "metadata": {},
   "source": [
    "# Feature Transformer Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66510b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1000,   50],\n",
       "       [2000,  100],\n",
       "       [1500,   75],\n",
       "       [3000,  150]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = np.array([[1000, 50], [2000, 100], [1500, 75], [3000, 150]])\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cae20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseTransformer(ABC):\n",
    "    \"\"\"Abstract base class for all transformers\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, X):\n",
    "        \"\"\"Learn parameters from X. Must be implemented by subclasses\"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, X):\n",
    "        \"\"\"Apply transformatiion using learned parameters\"\"\"\n",
    "        pass\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Convenience method: fir then transform\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820adca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standard_Scaler(BaseTransformer):\n",
    "    \"\"\"Standardize features by remvoing mean andscalingto unit  variance\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"Compute mean and std from training data\"\"\"\n",
    "        X = np.array(X)\n",
    "\n",
    "        # Compute mean and std\n",
    "        self.mean_ = np.mean(X, axis=0)\n",
    "        self.std_ = np.std(X, axis=0)\n",
    "\n",
    "        # Handle edge case\n",
    "        self.std_ = np.where(self.std_ == 0, 1, self.std_)\n",
    "\n",
    "        return self  # Return self for method chaining\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"Apply standardization using store mean and std\"\n",
    "        # Check if fitted\n",
    "        if self.mean_ is None or self.std_ is None:\n",
    "            raise ValueError(\"StandardScaler is not fitted. Call fit() first\")\n",
    "        X = np.array(X)\n",
    "        return (X - self.mean_) / self.std_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccaf714",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Log_Transformer(BaseTransformer):\n",
    "    \"\"\"Log transform doesn't need to fit anything, but we mark as fitted\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.fitted_ = False\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = np.array(X)\n",
    "\n",
    "        # Check for negative values\n",
    "        if np.any(X < 0):\n",
    "            raise ValueError(\n",
    "                \"Data contains negative values. LogTransformer does not support negative values\"\n",
    "            )\n",
    "\n",
    "        self.fitted_ = True\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = np.array(X)\n",
    "\n",
    "        if not self.fitted_:\n",
    "            raise ValueError(\"Log_Transformer not fitted. Call fit() first\")\n",
    "\n",
    "        # Check for negative values\n",
    "        if np.any(X < 0):\n",
    "            raise ValueError(\n",
    "                \"Data contains negative values. LogTransformer does not support negative values\"\n",
    "            )\n",
    "\n",
    "        # Use log1p to handle 0 values better\n",
    "        return np.log1p(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3c14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline:\n",
    "    \"\"\"Chain multiple transformers together\"\"\"\n",
    "\n",
    "    def __init__(self, transformers):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            transformers: List of transformer instances\n",
    "        \"\"\"\n",
    "        self.transformers = transformers\n",
    "\n",
    "    def fit(self, X):\n",
    "        X_transformed = np.array(X)\n",
    "\n",
    "        for transformer in self.transformers:\n",
    "            # Fit on current data\n",
    "            transformer.fit(X_transformed)\n",
    "            # Transform for next step\n",
    "            X_transformed = transformer.transform(X_transformed)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Apply all transformers seqeuntially\"\"\"\n",
    "        X_transformed = np.array(X)\n",
    "\n",
    "        for transformer in self.transformers:\n",
    "            # Transform data\n",
    "            X_transformed = transformer.transform(X_transformed)\n",
    "\n",
    "        return X_transformed\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit and transform in one step\"\"\"\n",
    "        self.fit(X)\n",
    "        return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a555f198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 3)\n",
      "(4, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create randomize train and test data\n",
    "X, y = make_classification(\n",
    "    n_samples=20,\n",
    "    n_features=3,\n",
    "    n_informative=2,\n",
    "    n_redundant=0,\n",
    "    n_classes=2,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Create train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Check shape\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a896913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.49496127 -0.58620189  2.33381747]\n",
      " [-1.9477101   0.69235584  0.24631018]\n",
      " [-0.10264818  0.29456159 -0.71507635]\n",
      " [ 0.94379629  0.00423813  0.08123043]\n",
      " [ 0.81852484 -2.03172154  0.57664785]\n",
      " [ 0.71598007 -0.4278377   0.20482236]\n",
      " [ 0.4288094   0.88337106 -0.28583051]\n",
      " [-1.04318652 -0.13895477 -1.75341917]\n",
      " [-0.8655255   1.30749947 -0.03580836]\n",
      " [-0.7882702  -0.0225576  -0.51034099]\n",
      " [-0.96760499  0.69537306 -1.98564645]\n",
      " [ 1.29767538  1.27364641 -0.04227517]\n",
      " [ 0.88218261  1.38861043 -0.27844868]\n",
      " [-0.49086041 -1.31036187  1.09634386]\n",
      " [ 1.61595082 -1.49798179  0.97444195]\n",
      " [-0.99207477 -0.52403883  0.09323159]]\n"
     ]
    }
   ],
   "source": [
    "transformers_list = [Log_Transformer(), Standard_Scaler()]\n",
    "pipeline = Pipeline(transformers_list)\n",
    "\n",
    "X_train_transformed = pipeline.fit_transform(abs(X_train))\n",
    "X_test_transformed = pipeline.transform(abs(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc82457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Standard_Scaler object at 0x1527ede50>\n"
     ]
    }
   ],
   "source": [
    "scaler = Standard_Scaler()\n",
    "print(scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727e9b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a06ff7e9",
   "metadata": {},
   "source": [
    "# Hashmaps to check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761012a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = [\n",
    "    {\"id\": \"txn_001\", \"user_id\": \"U100\", \"amount\": 50.00, \"timestamp\": 1000},\n",
    "    {\"id\": \"txn_002\", \"user_id\": \"U100\", \"amount\": 50.00, \"timestamp\": 1003},\n",
    "    {\"id\": \"txn_003\", \"user_id\": \"U100\", \"amount\": 50.00, \"timestamp\": 1500},\n",
    "    {\"id\": \"txn_004\", \"user_id\": \"U200\", \"amount\": 75.00, \"timestamp\": 1001},\n",
    "    {\"id\": \"txn_005\", \"user_id\": \"U200\", \"amount\": 75.00, \"timestamp\": 1008},\n",
    "    {\"id\": \"txn_006\", \"user_id\": \"U100\", \"amount\": 50.00, \"timestamp\": 1006},\n",
    "]\n",
    "T = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd54a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for duplicates in transactions\n",
    "def check_transaction_duplicates(transactions: list, T: float) -> list:\n",
    "    duplicate_index = []\n",
    "\n",
    "    for i in range(len(transactions)):\n",
    "        for j in range(i + 1, len(transactions)):\n",
    "            txn1 = transactions[i]\n",
    "            txn2 = transactions[j]\n",
    "\n",
    "            # Check the 3 conditions\n",
    "            same_user = txn1[\"user_id\"] == txn2[\"user_id\"]\n",
    "            same_amount = txn1[\"amount\"] == txn2[\"amount\"]\n",
    "            within_time = abs(txn1[\"timestamp\"] - txn2[\"timestamp\"]) <= T\n",
    "\n",
    "            if same_user and same_amount and within_time:\n",
    "                duplicate_index.append((txn1[\"id\"], txn2[\"id\"]))\n",
    "\n",
    "    return duplicate_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fc9fbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.00018405914306640625\n",
      "[('txn_001', 'txn_002'), ('txn_001', 'txn_006'), ('txn_002', 'txn_006'), ('txn_004', 'txn_005')]\n"
     ]
    }
   ],
   "source": [
    "# Complexity is O(n^2)\n",
    "start_time = time.time()\n",
    "duplicate_index = check_transaction_duplicates(transactions, T)\n",
    "print(f\"Time taken: {time.time() - start_time}\")\n",
    "print(duplicate_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0348a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {('U100',\n",
       "              50.0): [{'id': 'txn_001',\n",
       "               'user_id': 'U100',\n",
       "               'amount': 50.0,\n",
       "               'timestamp': 1000}, {'id': 'txn_002',\n",
       "               'user_id': 'U100',\n",
       "               'amount': 50.0,\n",
       "               'timestamp': 1003}, {'id': 'txn_003',\n",
       "               'user_id': 'U100',\n",
       "               'amount': 50.0,\n",
       "               'timestamp': 1500}, {'id': 'txn_006',\n",
       "               'user_id': 'U100',\n",
       "               'amount': 50.0,\n",
       "               'timestamp': 1006}],\n",
       "             ('U200',\n",
       "              75.0): [{'id': 'txn_004',\n",
       "               'user_id': 'U200',\n",
       "               'amount': 75.0,\n",
       "               'timestamp': 1001}, {'id': 'txn_005',\n",
       "               'user_id': 'U200',\n",
       "               'amount': 75.0,\n",
       "               'timestamp': 1008}]})"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "groups = defaultdict(list)\n",
    "\n",
    "for txn in transactions:\n",
    "    key = (txn[\"user_id\"], txn[\"amount\"])\n",
    "    groups[key].append(txn)\n",
    "\n",
    "display(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06db110d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_duplicate_transactions(\n",
    "    transactions: list[dict], T: int\n",
    ") -> list[tuple[str, str]]:\n",
    "    # Step 1: Group transactions by (user_id, amount)\n",
    "    groups = defaultdict(list)\n",
    "\n",
    "    for txn in transactions:\n",
    "        key = (txn[\"user_id\"], txn[\"amount\"])\n",
    "        groups[key].append(txn)\n",
    "\n",
    "    # Step 2: For each group, find duplicates\n",
    "    duplicates = []\n",
    "\n",
    "    for key, txn_list in groups.items():\n",
    "        txn_list.sort(key=lambda x: x[\"timestamp\"])\n",
    "\n",
    "        for i in range(len(txn_list)):\n",
    "            for j in range(i + 1, len(txn_list)):\n",
    "                time_diff = txn_list[j][\"timestamp\"] - txn_list[i][\"timestamp\"]\n",
    "\n",
    "                if time_diff > T:\n",
    "                    break\n",
    "\n",
    "                duplicates.append((txn_list[i][\"id\"], txn_list[j][\"id\"]))\n",
    "\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e829f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.0004107952117919922\n",
      "[('txn_001', 'txn_002'), ('txn_001', 'txn_006'), ('txn_002', 'txn_006'), ('txn_004', 'txn_005')]\n"
     ]
    }
   ],
   "source": [
    "# Complexity is O(n)\n",
    "start_time = time.time()\n",
    "duplicates = find_duplicate_transactions(transactions, T)\n",
    "print(f\"Time taken: {time.time() - start_time}\")\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de655055",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = (\"txn_001\", \"txn_002\")\n",
    "assert duplicates[0] == expected, f\"Expected {expected}, got {duplicates[0]}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a31066",
   "metadata": {},
   "source": [
    "# Price stream class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9fbb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceStream:\n",
    "    def __init__(self):\n",
    "        self.prices = deque()\n",
    "        self.total_sum = 0\n",
    "        self.count = 0\n",
    "        self.max_deque = deque()\n",
    "        self.min_deque = deque()\n",
    "\n",
    "    # Add new price\n",
    "    def add(self, price) -> None:\n",
    "        if isinstance(price, (list, tuple)):\n",
    "            for p in price:\n",
    "                self._add_single(p)\n",
    "        else:\n",
    "            self._add_single(price)\n",
    "\n",
    "    # Add new price helper\n",
    "    def _add_single(self, price: float) -> None:\n",
    "        self.prices.append(price)\n",
    "        self.total_sum += price\n",
    "        self.count += 1\n",
    "\n",
    "        # Imnplement max_deque\n",
    "        while self.max_deque and self.max_deque[-1] < price:\n",
    "            self.max_deque.pop()\n",
    "        self.max_deque.append(price)\n",
    "\n",
    "        # Imnplement min_deque\n",
    "        while self.min_deque and self.min_deque[-1] > price:\n",
    "            self.min_deque.pop()\n",
    "        self.min_deque.append(price)\n",
    "\n",
    "    # Get max price from the current stream\n",
    "    def get_max(self) -> float:\n",
    "        return self.max_deque[0]\n",
    "\n",
    "    # Get min price from the current stream\n",
    "    def get_min(self) -> float:\n",
    "        return self.min_deque[0]\n",
    "\n",
    "    # Get mean price from the current steam\n",
    "    def get_mean(self) -> float:\n",
    "        return self.total_sum / self.count\n",
    "\n",
    "    # Remove oldest price in stream\n",
    "    def remove_oldest(self) -> list:\n",
    "        oldest_px = self.prices.popleft()\n",
    "        self.total_sum -= oldest_px\n",
    "        self.count -= 1\n",
    "\n",
    "        if self.max_deque and self.max_deque[0] == oldest_px:\n",
    "            self.prices.popleft()\n",
    "\n",
    "        if self.min_deque and self.min_deque[0] == oldest_px:\n",
    "            self.prices.popleft()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Current stream: {self.prices}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a858b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = PriceStream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c30a11e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current stream: deque([10, 5, 8, 11, 10, 50, 5, 26, 9, 1, 9, 16, 27, 4])\n"
     ]
    }
   ],
   "source": [
    "stream.add(10)\n",
    "stream.add(5)\n",
    "stream.add(8)\n",
    "stream.add(11)\n",
    "stream.add([random.randint(1, 50) for _ in range(10)])\n",
    "print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7903eb8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "max_px = stream.get_max()\n",
    "print(max_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fa6624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "min_px = stream.get_min()\n",
    "print(min_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515655a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.642857142857142\n"
     ]
    }
   ],
   "source": [
    "mean_px = stream.get_mean()\n",
    "print(mean_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d2d24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current stream: deque([5, 8, 11, 10, 50, 5, 26, 9, 1, 9, 16, 27, 4])\n"
     ]
    }
   ],
   "source": [
    "stream.remove_oldest()\n",
    "print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c5828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.923076923076923\n"
     ]
    }
   ],
   "source": [
    "mean_px = stream.get_mean()\n",
    "print(mean_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872516a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "min_px = stream.get_min()\n",
    "print(min_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a95caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "min_px = stream.get_max()\n",
    "print(max_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cefc739",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
