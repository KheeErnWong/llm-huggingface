{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab0aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c0858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"zeroshot/twitter-financial-news-sentiment\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2565fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['$BYND - JPMorgan reels in expectations on Beyond Meat https://t.co/bd0xbFGjkT',\n",
       "  '$CCL $RCL - Nomura points to bookings weakness at Carnival and Royal Caribbean https://t.co/yGjpT2ReD3',\n",
       "  '$CX - Cemex cut at Credit Suisse, J.P. Morgan on weak building outlook https://t.co/KN1g4AWFIb'],\n",
       " 'label': [0, 0, 0]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa3f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da0c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet_text(text):\n",
    "    # 1. Remove URLs (http:// or https://)\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "\n",
    "    # 2. Remove Cashtags (e.g., $TSLA) and User Mentions (@user)\n",
    "    # Removing these forces the model to learn the sentiment from the words,\n",
    "    # not just the ticker/user which might be a good or bad stock.\n",
    "    text = re.sub(r\"[$@]\\w+\", \"\", text)\n",
    "\n",
    "    # 3. Remove excessive whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd90bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_text\"] = df[\"text\"].apply(clean_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce9db064",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"cleaned_text\"].tolist()\n",
    "labels = df[\"label\"].tolist()\n",
    "\n",
    "label_map = {0: \"negative\", 1: \"positive\", 2: \"neutral\"}\n",
    "\n",
    "labels_id = [label_map[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6229b152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "/Users/kheeern/AIAP/aiap/llm-huggingface/.venv/lib/python3.13/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "finbert = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"ProsusAI/finbert\",\n",
    "    tokenizer=\"ProsusAI/finbert\",\n",
    "    device=\"mps\",\n",
    "    return_all_scores=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62bb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasetÃ¥= Dataset.from_pandas(df[[\"cleaned_text\", \"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "# train_dataset = dataset[\"train\"]\n",
    "# test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"cleaned_text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c39b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "# tokenized_eval = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c98d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_train.set_format(\n",
    "#     type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "# )\n",
    "# tokenized_eval.set_format(\n",
    "#     type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_labels = 3\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"ProsusAI/finbert\", num_labels=num_labels\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9abea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366e8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer_args = TrainingArguments(\n",
    "#     output_dir=\"./finbert_twitter_results\",\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=4,\n",
    "#     per_device_eval_batch_size=4,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=100,\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=trainer_args,\n",
    "#     train_dataset=tokenized_train,\n",
    "#     eval_dataset=tokenized_eval,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     processing_class=tokenizer\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0781036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5dd8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_index(output_list: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the sentiment index from the model output.\n",
    "    The pipeline returns a list of dictionaries for each class\n",
    "    \"\"\"\n",
    "    sentiment_scores = {item[\"label\"]: item[\"score\"] for item in output_list}\n",
    "    sentiment_index = sentiment_scores.get(\"positive\", 0) - sentiment_scores.get(\n",
    "        \"negative\", 0\n",
    "    )\n",
    "    return sentiment_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb115f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated Output for a single tweet (\"Strong buy signal\")\n",
    "simulated_output = [\n",
    "    {\"label\": \"negative\", \"score\": 0.1},\n",
    "    {\"label\": \"neutral\", \"score\": 0.2},\n",
    "    {\"label\": \"positive\", \"score\": 0.7},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "32125a67",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m sentiment_index = \u001b[43mget_sentiment_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43msimulated_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCalculated Sentiment Index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msentiment_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mget_sentiment_index\u001b[39m\u001b[34m(output_list)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_sentiment_index\u001b[39m(output_list: \u001b[38;5;28mlist\u001b[39m) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Calculates the sentiment index from the model output.\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    The pipeline returns a list of dictionaries for each class\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     sentiment_scores = {\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m: item[\u001b[33m'\u001b[39m\u001b[33mscore\u001b[39m\u001b[33m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m output_list}\n\u001b[32m      7\u001b[39m     sentiment_index = (\n\u001b[32m      8\u001b[39m         sentiment_scores.get(\u001b[33m'\u001b[39m\u001b[33mpositive\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0\u001b[39m) - sentiment_scores.get(\u001b[33m'\u001b[39m\u001b[33mnegative\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m0\u001b[39m)\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment_index\n",
      "\u001b[31mTypeError\u001b[39m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "sentiment_index = get_sentiment_index(simulated_output)\n",
    "print(f\"Calculated Sentiment Index: {sentiment_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f1a5b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
