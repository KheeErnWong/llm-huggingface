{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab0aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    pipeline,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2c0858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"zeroshot/twitter-financial-news-sentiment\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f2565fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['$BYND - JPMorgan reels in expectations on Beyond Meat https://t.co/bd0xbFGjkT',\n",
       "  '$CCL $RCL - Nomura points to bookings weakness at Carnival and Royal Caribbean https://t.co/yGjpT2ReD3',\n",
       "  '$CX - Cemex cut at Credit Suisse, J.P. Morgan on weak building outlook https://t.co/KN1g4AWFIb'],\n",
       " 'label': [0, 0, 0]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa3f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da0c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet_text(text):\n",
    "    # 1. Remove URLs (http:// or https://)\n",
    "    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text)\n",
    "\n",
    "    # 2. Remove Cashtags (e.g., $TSLA) and User Mentions (@user)\n",
    "    # Removing these forces the model to learn the sentiment from the words,\n",
    "    # not just the ticker/user which might be a good or bad stock.\n",
    "    text = re.sub(r\"[$@]\\w+\", \"\", text)\n",
    "\n",
    "    # 3. Remove excessive whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcd90bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"cleaned_text\"] = df[\"text\"].apply(clean_tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce9db064",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df[\"cleaned_text\"].tolist()\n",
    "labels = df[\"label\"].tolist()\n",
    "\n",
    "label_map = {0: \"negative\", 1: \"positive\", 2: \"neutral\"}\n",
    "\n",
    "labels_id = [label_map[i] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6229b152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps\n",
      "/Users/kheeern/AIAP/aiap/llm-huggingface/.venv/lib/python3.13/site-packages/transformers/pipelines/text_classification.py:111: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "finbert = pipeline(\n",
    "    \"sentiment-analysis\",\n",
    "    model=\"ProsusAI/finbert\",\n",
    "    tokenizer=\"ProsusAI/finbert\",\n",
    "    device=\"mps\",\n",
    "    return_all_scores=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa78200",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"Strong buy signal for $AAPL! The company's earnings exceeded expectations.\",\n",
    "    \"I'm worried about the recent downturn in the market. $TSLA might be in trouble.\",\n",
    "    \"The stock price of $AMZN is stable, no significant changes expected.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e366e99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'positive', 'score': 0.9539347290992737}, {'label': 'negative', 'score': 0.02289365604519844}, {'label': 'neutral', 'score': 0.0231715627014637}], [{'label': 'positive', 'score': 0.009392853826284409}, {'label': 'negative', 'score': 0.9575983881950378}, {'label': 'neutral', 'score': 0.033008672297000885}], [{'label': 'positive', 'score': 0.05344356968998909}, {'label': 'negative', 'score': 0.017642412334680557}, {'label': 'neutral', 'score': 0.9289140105247498}]]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62bb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset= Dataset.from_pandas(df[[\"cleaned_text\", \"label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba292d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "# train_dataset = dataset[\"train\"]\n",
    "# test_dataset = dataset[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f7b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119a62e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_function(examples):\n",
    "#     return tokenizer(examples[\"cleaned_text\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c39b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_train = train_dataset.map(tokenize_function, batched=True)\n",
    "# tokenized_eval = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860c98d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_train.set_format(\n",
    "#     type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "# )\n",
    "# tokenized_eval.set_format(\n",
    "#     type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a6fb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_labels = 3\n",
    "\n",
    "# model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"ProsusAI/finbert\", num_labels=num_labels\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9abea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_pred):\n",
    "#     logits, labels = eval_pred\n",
    "#     predictions = np.argmax(logits, axis=-1)\n",
    "#     return accuracy_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366e8fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer_args = TrainingArguments(\n",
    "#     output_dir=\"./finbert_twitter_results\",\n",
    "#     num_train_epochs=3,\n",
    "#     per_device_train_batch_size=4,\n",
    "#     per_device_eval_batch_size=4,\n",
    "#     warmup_steps=500,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=100,\n",
    "#     eval_strategy=\"epoch\",\n",
    "#     save_strategy=\"epoch\",\n",
    "#     load_best_model_at_end=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44f1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=trainer_args,\n",
    "#     train_dataset=tokenized_train,\n",
    "#     eval_dataset=tokenized_eval,\n",
    "#     compute_metrics=compute_metrics,\n",
    "#     processing_class=tokenizer\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0781036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dd8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_index(output_list: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the sentiment index from the model output.\n",
    "    The pipeline returns a list of dictionaries for each class\n",
    "    \"\"\"\n",
    "    sentiment_scores = {item[\"label\"]: item[\"score\"] for item in output_list}\n",
    "    sentiment_index = sentiment_scores.get(\"positive\", 0) - sentiment_scores.get(\n",
    "        \"negative\", 0\n",
    "    )\n",
    "    return sentiment_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b8f1a5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Strong buy signal for $AAPL! The company's earnings exceeded expectations.\n",
      "Sentiment Scores: [{'label': 'positive', 'score': 0.9539347290992737}, {'label': 'negative', 'score': 0.02289365604519844}, {'label': 'neutral', 'score': 0.0231715627014637}]\n",
      "Sentiment index: 0.9310410730540752\n",
      "\n",
      "Text: I'm worried about the recent downturn in the market. $TSLA might be in trouble.\n",
      "Sentiment Scores: [{'label': 'positive', 'score': 0.009392853826284409}, {'label': 'negative', 'score': 0.9575983881950378}, {'label': 'neutral', 'score': 0.033008672297000885}]\n",
      "Sentiment index: -0.9482055343687534\n",
      "\n",
      "Text: The stock price of $AMZN is stable, no significant changes expected.\n",
      "Sentiment Scores: [{'label': 'positive', 'score': 0.05344356968998909}, {'label': 'negative', 'score': 0.017642412334680557}, {'label': 'neutral', 'score': 0.9289140105247498}]\n",
      "Sentiment index: 0.03580115735530853\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = finbert(text)\n",
    "for i, res in enumerate(results):\n",
    "    print(f\"Text: {text[i]}\")\n",
    "    print(f\"Sentiment Scores: {res}\")\n",
    "    print(f\"Sentiment index: {get_sentiment_index(res)}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f23a5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-huggingface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
